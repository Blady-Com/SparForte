------------------------------------------------------------------------------
-- Berekeley Hash Files Package Parser                                      --
--                                                                          --
-- Part of SparForte                                                        --
------------------------------------------------------------------------------
--                                                                          --
--            Copyright (C) 2001-2016 Free Software Foundation              --
--                                                                          --
-- This is free software;  you can  redistribute it  and/or modify it under --
-- terms of the  GNU General Public License as published  by the Free Soft- --
-- ware  Foundation;  either version 2,  or (at your option) any later ver- --
-- sion.  This is distributed in the hope that it will be useful, but WITH- --
-- OUT ANY WARRANTY;  without even the  implied warranty of MERCHANTABILITY --
-- or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License --
-- for  more details.  You should have  received  a copy of the GNU General --
-- Public License  distributed with this;  see file COPYING.  If not, write --
-- to  the Free Software Foundation,  59 Temple Place - Suite 330,  Boston, --
-- MA 02111-1307, USA.                                                      --
--                                                                          --
-- This is maintained at http://www.sparforte.com                           --
--                                                                          --
------------------------------------------------------------------------------
pragma ada_2005;

with text_io;use text_io;

with
    Interfaces.C,
    ada.exceptions,
    gnat.directory_operations,
    bush_os,
    user_io,
    world,
    scanner,
    scanner_res,
    string_util,
    parser,
    parser_aux,
    parser_params,
    parser_bdb;

#if BDB
with
    bdb,
    bdb_constants;
#end if;

use
    ada.exceptions,
    gnat.directory_operations,
    world,
    user_io,
    scanner,
    scanner_res,
    string_util,
    parser,
    parser_aux,
    parser_params,
    parser_bdb;
#if BDB
use
    bdb,
    bdb_constants;
#end if;

package body parser_hash_io is

------------------------------------------------------------------------------
-- Utility subprograms
------------------------------------------------------------------------------

procedure CheckFileIsInitialized( fileId : identifier ) is
begin
  if identifiers( fileId ).genKind = eof_t then
     err( "new_file has not been called to initialize the file" );
  end if;
end CheckFileIsInitialized;

procedure ParseSingleFileParameter( fileId : out identifier ) is
begin
  ParseSingleInOutParameter( fileId, hash_file_t );
  CheckFileIsInitialized( fileId );
end ParseSingleFileParameter;

procedure ParseFirstFileParameter( fileId : out identifier ) is
begin
  ParseFirstInOutParameter( fileId, hash_file_t );
  CheckFileIsInitialized( fileId );
end ParseFirstFileParameter;

procedure ParseNextFileParameter( fileId : out identifier ) is
begin
  ParseNextInOutParameter( fileId, hash_file_t );
  CheckFileIsInitialized( fileId );
end ParseNextFileParameter;

procedure ParseLastFileParameter( fileId : out identifier ) is
begin
  ParseLastInOutParameter( fileId, hash_file_t );
  CheckFileIsInitialized( fileId );
end ParseLastFileParameter;

procedure CheckCursorIsInitialized( cursId : identifier ) is
begin
  if identifiers( cursId ).genKind = eof_t then
     err( "new_cursor has not been called to initialize the cursor" );
  end if;
end CheckCursorIsInitialized;

procedure ParseSingleCursorParameter( cursId : out identifier ) is
begin
  ParseSingleInOutParameter( cursId, hash_cursor_t );
  CheckCursorIsInitialized( cursId );
end ParseSingleCursorParameter;

procedure ParseFirstCursorParameter( cursId : out identifier ) is
begin
  ParseFirstInOutParameter( cursId, hash_cursor_t );
  CheckCursorIsInitialized( cursId );
end ParseFirstCursorParameter;

procedure ParseNextCursorParameter( cursId : out identifier ) is
begin
  ParseNextInOutParameter( cursId, hash_cursor_t );
  CheckCursorIsInitialized( cursId );
end ParseNextCursorParameter;

procedure ParseLastCursorParameter( cursId : out identifier ) is
begin
  ParseLastInOutParameter( cursId, hash_cursor_t );
  CheckCursorIsInitialized( cursId );
end ParseLastCursorParameter;


------------------------------------------------------------------------------
-- Parser subprograms
------------------------------------------------------------------------------

#if BDB

procedure ParseHashNewFile is
  -- Syntax: hash.new_file( f, t );
  -- Ada:    N/A
  resId : resHandleId;
  ref : reference;
  genKindId : identifier;
begin
  expect( hash_new_file_t );
  ParseFirstOutParameter( ref, hash_file_t );
  baseTypesOK( ref.kind, hash_file_t );
  expect( symbol_t, "," );
  ParseIdentifier( genKindId );
  if class_ok( genKindId, typeClass, subClass ) then
     -- DEBUG: trying aggregates
     null;
     --if identifiers( genKindId ).list then
     --   err( "element type should be a scalar type" );
     -- elsif identifiers( getBaseType( genKindId ) ).kind = root_record_t then
     --    err( "element type should be a scalar type" );
     --end if;
  end if;
  identifiers( ref.id ).genKind := genKindId;
  expect( symbol_t, ")" );
  if isExecutingCommand then
     identifiers( ref.id ).resource := true;
     declareResource( resId, hash_file, blocks_top );
     AssignParameter( ref, to_unbounded_string( resId ) );
  end if;
end ParseHashNewFile;

#else

pragma warnings( off );
-- Hide unused parameters warnings

procedure ParseHashNewFile is
begin
  err( "bdb support not configured" );
end ParseHashNewFile;

#end if;
#if BDB

procedure ParseHashClear is
  -- Syntax: hash.clear( f );
  -- Ada:    N/A;
  fileId   : identifier;
  theFile  : resPtr;
begin
  expect( hash_clear_t );
  ParseSingleFileParameter( fileId );
  if isExecutingCommand then
     begin
       -- close the file / environment, if they are still open.  This doesn't
       -- close any cursors.
       findResource( to_resource_id( identifiers( fileId ).value ), theFile );
       if theFile.hash.isOpen then
          Close( theFile.hash.session );
          Close( theFile.hash.env );
          theFile.hash.isOpen := false;
       end if;
     exception when msg: berkeley_error =>
       err( exception_message( msg ) );
     end;
  end if;
end ParseHashClear;

#else

procedure ParseHashClear is
begin
  err( "bdb support not configured" );
end ParseHashClear;

#end if;
#if BDB

procedure ParseHashCreate is
  -- Syntax: hash.create( f, path, keyLen, valLen );
  -- Ada:    hash.create( f, path, keyLen, valLen );
  -- this is impacted by --verbse
  fileId     : identifier;
  theFile    : resPtr;
  fname_val  : unbounded_string;
  fname_type : identifier;
  keyLen     : interfaces.C.size_t;
  keyLenExpr : unbounded_string;
  keyLenType : identifier;
  valLen     : interfaces.C.size_t;
  valLenExpr : unbounded_string;
  valLenType : identifier;
begin
  if rshOpt then
     err( "create not allowed in a " & optional_bold( "restricted shell" ) );
  end if;
  expect( hash_create_t );
  -- NOTE: normally this is an out parameter but it is a resource so it
  -- must be initialized separately.
  ParseFirstFileParameter( fileId );
  ParseNextStringParameter( fname_val, fname_type, string_t );
  ParseNextNumericParameter( keyLenExpr, keyLenType, positive_t );
  ParseLastNumericParameter( valLenExpr, valLenType, positive_t );
  if isExecutingCommand then
     begin
        keyLen := Interfaces.C.size_t'value( to_string( keyLenExpr ) );
     exception when others =>
        err( "key length must be" & Interfaces.C.size_t'first'img & ".." & Interfaces.C.size_t'last'img );
     end;
     begin
        valLen := Interfaces.C.size_t'value( to_string( valLenExpr ) );
     exception when others =>
        err( "value length must be" & Interfaces.C.size_t'first'img & ".." & Interfaces.C.size_t'last'img );
     end;

     declare
        filename : string := base_name( to_string( fname_val ) );
        dirname  : string := dir_name( to_string( fname_val ) );
        dirname2 : unbounded_string;
        pwdId : identifier;
     begin
        findResource( to_resource_id( identifiers( fileId ).value ), theFile );

        init( theFile.hash.env );

        -- berkeley db paths must be absolute paths when creating (opening
        -- an exisiting data file is OK for relative paths)

        dirname2 := to_unbounded_string( dirname );
        if dirname = "." then
           dirname2 := null_unbounded_string;
        elsif element( dirname2, 1 ) /= '/' then
           findIdent( to_unbounded_string( "PWD" ), pwdId );
           dirname2 := identifiers( pwdId ).value & "/" & dirname;
        end if;
        if trace then
           put_trace( "Base directory is '" & to_string( dirname2 ) & "'" );
        end if;

        -- Berkeley puts the files in the current directory, though you can
        -- move the env because it is shared.  To put the project in a specific
        -- directory, you have you configure it.  A sophisiticated setup would
        -- place all of these in different directories.
        --
        -- For our purposes (simple files), keep everything in one directory

        if length( dirname2 ) > 0 then
           begin
              set_data_dir( theFile.hash.env, to_string( dirname2 ) );
           exception when msg: berkeley_error =>
              err( exception_message( msg ) & " on setting the data directory" );
           end;
           begin
              set_tmp_dir( theFile.hash.env, to_string( dirname2 ) );
           exception when msg: berkeley_error =>
              err( exception_message( msg ) & " on setting the temp directory"  );
           end;
           begin
              set_lg_dir( theFile.hash.env, to_string( dirname2 ) );
           exception when msg: berkeley_error =>
              err( exception_message( msg ) & " on setting the logging directory"  );
           end;
           begin
              if verboseOpt then
                 set_verbose( theFile.hash.env, 0, 1 );
              end if;
           exception when msg: berkeley_error =>
              err( exception_message( msg ) & " on changing verbose setting"  );
           end;
        end if;

        -- Create an environment

        begin
           create( theFile.hash.env,
                to_string( dirname2 ),
                -- I assume we don't need logging or transactions but
                -- they could be implemented.
                DB_E_OPEN_INIT_LOCK OR
                DB_E_OPEN_INIT_MPOOL,
                0 );
           theFile.hash.envhome := dirname2;
           exception when msg: berkeley_error =>
              err( exception_message( msg ) & " on creating the environment" );
           end;

        -- Create the file
        new_berkeley_session(
           theFile.hash.session,
           theFile.hash.env,
           keyLen,
           valLen );
        begin
           create( theFile.hash.session, filename, "", DB_HASH, 0, 0 );
        exception when msg: berkeley_error =>
           err( exception_message( msg ) & " on creating the data file"  );
        end;
        theFile.hash.isOpen := true;
        theFile.hash.name := fname_val;

        declare
           cnt : natural;
        begin
           truncate( theFile.hash.session, cnt );
           if trace and cnt > 0 then
              put_trace( cnt'img & " records were erased" );
           end if;
        exception when msg: berkeley_error =>
           err( exception_message( msg ) & " on truncating the data file"  );
        end;
     --exception when berkeley_error:s =>
     --   err( to_string( last_error( theFile.hash.session ) );
     end;
  end if;
end ParseHashCreate;

#else

procedure ParseHashCreate is
begin
  err( "bdb support not configured" );
end ParseHashCreate;

#end if;
#if BDB

procedure ParseHashClose is
  -- Syntax: hash.create( f );
  -- Ada:    hash.create( f );
  fileId     : identifier;
  theFile    : resPtr;
begin
  expect( hash_close_t );
  ParseSingleFileParameter( fileId );
  if isExecutingCommand then
     begin
        findResource( to_resource_id( identifiers( fileId ).value ), theFile );
        close( theFile.hash.session );
        close( theFile.hash.env );
        theFile.hash.isOpen := false;
      exception when msg: berkeley_error =>
        err( exception_message( msg ) );
     end;
  end if;
end ParseHashClose;

#else

procedure ParseHashClose is
begin
  err( "bdb support not configured" );
end ParseHashClose;

#end if;
#if BDB

procedure ParseHashOpen is
  -- Syntax: hash.open( f, path, keyLen, valLen );
  -- Ada:    hash.open( f, path, keyLen, valLen );
  -- this is impacted by --verbse
  fileId     : identifier;
  theFile    : resPtr;
  fname_val  : unbounded_string;
  fname_type : identifier;
  keyLen     : interfaces.C.size_t;
  keyLenExpr : unbounded_string;
  keyLenType : identifier;
  valLen     : interfaces.C.size_t;
  valLenExpr : unbounded_string;
  valLenType : identifier;
begin
  expect( hash_open_t );
  -- NOTE: normally this is an out parameter but it is a resource so it
  -- must be initialized separately.
  ParseFirstFileParameter( fileId );
  ParseNextStringParameter( fname_val, fname_type, string_t );
  -- TODO: can this be dynamic?
  ParseNextNumericParameter( keyLenExpr, keyLenType, positive_t );
  ParseLastNumericParameter( valLenExpr, valLenType, positive_t );
  if isExecutingCommand then
     begin
        keyLen := Interfaces.C.size_t'value( to_string( keyLenExpr ) );
     exception when others =>
        err( "key length must be" & Interfaces.C.size_t'first'img & ".." & Interfaces.C.size_t'last'img );
     end;
     begin
        valLen := Interfaces.C.size_t'value( to_string( valLenExpr ) );
     exception when others =>
        err( "value length must be" & Interfaces.C.size_t'first'img & ".." & Interfaces.C.size_t'last'img );
     end;

     declare
        filename : string := base_name( to_string( fname_val ) );
        dirname  : string := dir_name( to_string( fname_val ) );
        dirname2 : unbounded_string;
        pwdId : identifier;
     begin
        -- TODO: pathname handling
        findResource( to_resource_id( identifiers( fileId ).value ), theFile );

        -- Create an environment
        init( theFile.hash.env );

        -- berkeley db paths must be absolute paths when creating (opening
        -- an exisiting data file is OK for relative paths).  We're doing this
        -- here to be consistent with create but it shouldn't be necessary

        dirname2 := to_unbounded_string( dirname );
        if dirname = "." then
           dirname2 := null_unbounded_string;
        elsif rshOpt then
           -- TODO: probably could be in directories in current PATH as well
           err( "file must be in current directory in a " & optional_bold( "restricted shell" ) );
        elsif element( dirname2, 1 ) /= '/' then
           findIdent( to_unbounded_string( "PWD" ), pwdId );
           dirname2 := identifiers( pwdId ).value & "/" & dirname;
        end if;
        if trace then
           put_trace( "Base directory is '" & to_string( dirname2 ) & "'" );
        end if;

        -- Berkeley puts the files in the current directory, though you can
        -- move the env because it is shared.  To put the project in a specific
        -- directory, you have you configure it.  A sophisiticated setup would
        -- place all of these in different directories.
        --
        -- For our purposes (simple files), keep everything in one directory

        if length( dirname2 ) > 0 then
           begin
              set_data_dir( theFile.hash.env, to_string( dirname2 ) );
           exception when msg: berkeley_error =>
              err( exception_message( msg ) & " on setting the data directory" );
           end;
           begin
              set_tmp_dir( theFile.hash.env, to_string( dirname2 ) );
           exception when msg: berkeley_error =>
              err( exception_message( msg ) & " on setting the temp directory"  );
           end;
           begin
              set_lg_dir( theFile.hash.env, to_string( dirname2 ) );
           exception when msg: berkeley_error =>
              err( exception_message( msg ) & " on setting the logging directory"  );
           end;
           begin
              if verboseOpt then
                 set_verbose( theFile.hash.env, 0, 1 );
              end if;
           exception when msg: berkeley_error =>
              err( exception_message( msg ) & " on changing verbose setting"  );
           end;
        end if;

        begin
           open( theFile.hash.env,
                to_string( dirname2 ),
                -- I assume we don't need logging or transactions but
                -- they could be implemented.
                DB_E_OPEN_INIT_LOCK OR
                DB_E_OPEN_INIT_MPOOL,
                0 );
           theFile.hash.envhome := dirname2;
           exception when msg: berkeley_error =>
              err( exception_message( msg ) & " on opening the environment" );
           end;

        -- Create the file
        new_berkeley_session(
           theFile.hash.session,
           theFile.hash.env,
           keyLen,
           valLen );

        begin
           open( theFile.hash.session, filename, "", DB_HASH, 0, 0 );
        exception when msg: berkeley_error =>
           err( exception_message( msg ) & " on opening the data file"  );
        end;
        theFile.hash.isOpen := true;
        theFile.hash.name := fname_val;
     end;
  end if;
end ParseHashOpen;

#else

procedure ParseHashOpen is
begin
  err( "bdb support not configured" );
end ParseHashOpen;

#end if;
#if BDB

procedure ParseHashIsOpen( result : out unbounded_string; kind : out identifier ) is
  -- Syntax: b := hash.is_open( f );
  -- Ada:    N/A
  fileId     : identifier;
  theFile    : resPtr;
begin
  kind := boolean_t;
  expect( hash_is_open_t );
  ParseSingleFileParameter( fileId );
  if isExecutingCommand then
     begin
        findResource( to_resource_id( identifiers( fileId ).value ), theFile );
        result := to_bush_boolean( theFile.hash.isOpen );
     exception when berkeley_error =>
        result := to_bush_boolean( false );
     end;
  end if;
end ParseHashIsOpen;

#else

procedure ParseHashIsOpen( result : out unbounded_string; kind : out identifier ) is
begin
  err( "bdb support not configured" );
end ParseHashIsOpen;

#end if;
#if BDB

procedure ParseHashName( result : out unbounded_string; kind : out identifier ) is
  -- Syntax: b := hash.name( f );
  -- Ada:    N/A
  fileId     : identifier;
  theFile    : resPtr;
begin
  kind := string_t;
  expect( hash_name_t );
  ParseSingleFileParameter( fileId );
  if isExecutingCommand then
     begin
        findResource( to_resource_id( identifiers( fileId ).value ), theFile );
        result := theFile.hash.name;
     end;
  end if;
end ParseHashName;

#else

procedure ParseHashName( result : out unbounded_string; kind : out identifier ) is
begin
  err( "bdb support not configured" );
end ParseHashName;

#end if;
#if BDB

procedure ParseHashDelete is
  -- Syntax: hash.delete( f );
  -- Ada:    bdb.remove( f );
  -- TODO:   option to the keep environment in case other files use it
  fileId     : identifier;
  theFile    : resPtr;
begin
  if rshOpt then
     err( "delete not allowed in a " & optional_bold( "restricted shell" ) );
  end if;
  expect( hash_delete_t );
  ParseSingleFileParameter( fileId );
  if isExecutingCommand then
     begin
        findResource( to_resource_id( identifiers( fileId ).value ), theFile );
        if theFile.hash.isOpen then
           begin
              close( theFile.hash.session );
           exception when msg: berkeley_error =>
              err( exception_message( msg ) & " on closing the data file"  );
           end;
        end if;

        begin
           dbremove( theFile.hash.env,
             to_string( theFile.hash.name ),
             "",
             0 );
        exception when msg: berkeley_error =>
            err( exception_message( msg ) & " on removing the data file"  );
        end;

        -- keep the environment
        if theFile.hash.isOpen then
           begin
              close( theFile.hash.env );
           exception when msg: berkeley_error =>
              err( exception_message( msg ) & " on closing the environment"  );
           end;
          -- remove( theFile.hash.env, dbhome )
        end if;

        begin
           init( theFile.hash.env );
           remove( theFile.hash.env, to_string( theFile.hash.envhome ) );
        exception when msg: berkeley_error =>
           err( exception_message( msg ) & " on removing the environment"  );
        end;
        theFile.hash.isOpen := false;
     exception when storage_error =>
        err( "storage_error raised" );
     when constraint_error =>
        err( "constraint_error raised" );
     when others =>
        err_exception_raised;
     end;
  end if;
end ParseHashDelete;

#else

procedure ParseHashDelete is
begin
  err( "bdb support not configured" );
end ParseHashDelete;

#end if;
#if BDB

procedure ParseHashSet is
  -- Syntax: hash.set( f, key, value );
  -- Ada:    bdb.put( f, key, value );
  fileId     : identifier;
  theFile    : resPtr;
  keyExpr    : unbounded_string;
  keyType    : identifier;
  valExpr    : unbounded_string;
  valType    : identifier;
  valId      : identifier;
  isRecord   : boolean := false;
  isArray    : boolean := false;
  genKindId  : identifier;
begin
  if rshOpt then
     err( "set not allowed in a " & optional_bold( "restricted shell" ) );
  end if;
  expect( hash_set_t );
  ParseFirstFileParameter( fileId );
  ParseNextStringParameter( keyExpr, keyType, string_t );
  expect( symbol_t, "," );
  genKindId := identifiers( fileId ).genKind;
  -- This assumes we don't have aggregate expressions yet.
  -- record?
  if identifiers( getBaseType( genKindId ) ).kind = root_record_t then
     isRecord := true;
     ParseIdentifier( valId );
     genTypesOk( identifiers( valId ).kind, genKindId );
  -- array?
  elsif identifiers( genKindId ).list then
     isArray := true;
     ParseIdentifier( valId );
     genTypesOk( identifiers( valId ).kind, genKindId );
  -- normal (scalar) expression?
  else
    ParseGenItemParameter( valExpr, valType, genKindId );
  end if;
  expect( symbol_t, ")" );
  if isExecutingCommand then
     if isRecord then
        declare
           jsonString : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value ), theFile );
           DoRecordToJson( jsonString, valId );
           put( theFile.hash.session, to_string( keyExpr ), to_string( jsonString ) );
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        end;
     elsif isArray then
        declare
           jsonString : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value ), theFile );
           DoArrayToJson( jsonString, valId );
           put( theFile.hash.session, to_string( keyExpr ), to_string( jsonString ) );
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        end;
     else
        -- normal scalar expression
        begin
           findResource( to_resource_id( identifiers( fileId ).value ), theFile );
           put( theFile.hash.session, to_string( keyExpr ), to_string( valExpr ) );
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        end;
     end if;
  end if;
end ParseHashSet;

#else

procedure ParseHashSet is
begin
  err( "bdb support not configured" );
end ParseHashSet;

#end if;
#if BDB

procedure ParseHashGet is
  -- Syntax: hash.get( f, k, v );
  -- Ada:    v := bdb.get( f, k );
  -- This was originally a function but turned into a procedure because
  -- v can now be an aggregate (and we currently cannot return aggregates
  -- from a function)
  fileId     : identifier;
  theFile    : resPtr;
  keyExpr    : unbounded_string;
  keyType    : identifier;
  itemRef    : reference;
  isRecord   : boolean := false;
  isArray    : boolean := false;
  genKindId  : identifier;
begin
  -- TODO: null string instead of exception to parallel dht
  expect( hash_get_t );
  ParseFirstFileParameter( fileId );
  genKindId := identifiers( fileId ).genKind;
  ParseNextStringParameter( keyExpr, keyType, string_t );
  expect( symbol_t, "," );
  -- This assumes we don't have aggregate expressions yet.
  -- record?
  if identifiers( getBaseType( genKindId ) ).kind = root_record_t then
     -- ParseOutParam doesn't handle full records or arrays
     isRecord := true;
     ParseIdentifier( itemRef.id );
     genTypesOk( identifiers( itemRef.id ).kind, genKindId );
  -- array?
  elsif identifiers( genKindId ).list then
     -- ParseOutParam doesn't handle full records or arrays
     isArray := true;
     ParseIdentifier( itemRef.id );
     genTypesOk( identifiers( itemRef.id ).kind, genKindId );
     --ParseLastOutParameter(  itemRef, genKindId );
  else
     -- This will still auto-declare scalars
     ParseOutParameter(  itemRef, genKindId );
  end if;
  expect( symbol_t, ")" );
  if isExecutingCommand then
     if isRecord then
        declare
           jsonString : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value ), theFile );
           get( theFile.hash.session, to_string( keyExpr ), jsonString );
           DoJsonToRecord( itemRef.id, jsonString );
        exception when msg: berkeley_error =>
           if last_error( theFile.hash.session ) = DB_NOTFOUND then
              err( "key not found" );
           else
               err( exception_message( msg ) );
           end if;
        end;
     elsif isArray then
        declare
           jsonString : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value ), theFile );
           get( theFile.hash.session, to_string( keyExpr ), jsonString );
           DoJsonToArray( itemRef.id, jsonString );
        exception when msg: berkeley_error =>
           if last_error( theFile.hash.session ) = DB_NOTFOUND then
              err( "key not found" );
           else
               err( exception_message( msg ) );
           end if;
        end;
     else
        declare
           result : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value ), theFile );
           get( theFile.hash.session, to_string( keyExpr ), result );
           AssignParameter( itemRef, result );
        exception when msg: berkeley_error =>
           if last_error( theFile.hash.session ) = DB_NOTFOUND then
              err( "key not found" );
           else
               err( exception_message( msg ) );
           end if;
        end;
     end if;
  end if;
end ParseHashGet;

#else

procedure ParseHashGet is
begin
  err( "bdb support not configured" );
end ParseHashGet;

#end if;
#if BDB

procedure ParseHashHasElement( result : out unbounded_string; kind : out identifier ) is
  -- Syntax: v := hash.has_element( f, k );
  -- Ada:    bdb.exists( f, k );
  fileId     : identifier;
  theFile    : resPtr;
  keyExpr    : unbounded_string;
  keyType    : identifier;
begin
  kind := boolean_t;
  expect( hash_has_element_t );
  ParseFirstFileParameter( fileId );
  ParseLastStringParameter( keyExpr, keyType, string_t );
  if isExecutingCommand then
     begin
        findResource( to_resource_id( identifiers( fileId ).value ), theFile );
        exists( theFile.hash.session, to_string( keyExpr ) );
        result := to_bush_boolean( true );
     exception when berkeley_error =>
        result := to_bush_boolean( false );
     end;
  end if;
end ParseHashHasElement;

#else

procedure ParseHashHasElement( result : out unbounded_string; kind : out identifier ) is
begin
  err( "bdb support not configured" );
end ParseHashHasElement;

#end if;
#if BDB

procedure ParseHashRemove is
  -- Syntax: v := hash.remove( f, k | c );
  -- Ada:    bdb.delete( f, k | c );
  fileId     : identifier;
  theFile    : resPtr;
  cursId     : identifier;
  theCurs    : resPtr;
  keyExpr    : unbounded_string;
  keyType    : identifier;
begin
  if rshOpt then
     err( "remove not allowed in a " & optional_bold( "restricted shell" ) );
  end if;
  expect( hash_remove_t );
  ParseFirstFileParameter( fileId );
  expect( symbol_t, "," );
  if getbaseType( identifiers( token ).kind ) = hash_cursor_t then
     ParseIdentifier( cursId );
     genTypesOk( identifiers( fileId ).genKind, identifiers( cursId ).genKind );
  else
     ParseExpression( keyExpr, keyType );
     baseTypesOk( keyType, uni_string_t );
  end if;
  expect( symbol_t, ")" );
  if isExecutingCommand then
     findResource( to_resource_id( identifiers( fileId ).value ), theFile );
     if cursId /= eof_t then
        begin
          findResource( to_resource_id( identifiers( cursId ).value ), theCurs );
          delete( theFile.hash.session, theCurs.hash_cur );
        exception when msg: berkeley_error =>
            err( exception_message( msg ) );
        end;
     else
        begin
           delete( theFile.hash.session, to_string( keyExpr ) );
        exception when msg: berkeley_error =>
           if last_error( theFile.hash.session ) = DB_NOTFOUND then
              err( "key not found" );
           else
              err( exception_message( msg ) );
           end if;
        end;
     end if;
  end if;
end ParseHashRemove;

#else

procedure ParseHashRemove is
begin
  err( "bdb support not configured" );
end ParseHashRemove;

#end if;
#if BDB

procedure ParseHashIncrement is
  -- Syntax: hash.increment( f, s [,n] );
  -- Ada:    N/A
  fileId     : identifier;
  theFile    : resPtr;
  keyExpr  : unbounded_string;
  keyType  : identifier;
  amtExpr  : unbounded_string;
  amtType  : identifier;
  hasAmt   : boolean := false;
  oldItem  : unbounded_string;
  oldItemValue : long_float;
begin
  if rshOpt then
     err( "increment not allowed in a " & optional_bold( "restricted shell" ) );
  end if;
  expect( hash_increment_t );
  ParseFirstFileParameter( fileId );
  if getUniType( identifiers( fileId ).genKind ) /= uni_numeric_t then
     err( "increment requires a numeric item type" );
  end if;
  ParseNextStringParameter( keyExpr, keyType, uni_string_t );
  if token = symbol_t and identifiers( token ).value = "," then
     hasAmt := true;
     ParseLastNumericParameter( amtExpr, amtType, natural_t );
  elsif token = symbol_t and identifiers( token ).value = ")" then
     expect( symbol_t, ")" );
  else
     err( ", or ) expected" );
  end if;
  if isExecutingCommand then
     begin
       findResource( to_resource_id( identifiers( fileId ).value ), theFile );

       get( theFile.hash.session, to_string( keyExpr ), oldItem );
       -- berkeley throws exception on not found
       --if oldItem /= null_unbounded_string then
          oldItemValue := to_numeric( oldItem );
          if hasAmt then
             put( theFile.hash.session, to_string( keyExpr ),  to_string( to_unbounded_string( oldItemValue + long_float( natural( to_numeric( amtExpr ) ) ) ) ) );
          else
             put( theFile.hash.session, to_string( keyExpr ), to_string( to_unbounded_string( oldItemValue + 1.0 ) ) );
          end if;
       --end if;
     exception when storage_error =>
       err( "storage error raised" );
     when constraint_error =>
       err( "constraint error raised" );
     when msg: berkeley_error =>
       if last_error( theFile.hash.session ) = DB_NOTFOUND then
          err( "key not found" );
       else
          err( exception_message( msg ) );
       end if;
     end;
  end if;
end ParseHashIncrement;

#else

procedure ParseHashIncrement is
begin
  err( "bdb support not configured" );
end ParseHashIncrement;

#end if;
#if BDB

procedure ParseHashDecrement is
  -- Syntax: hash.decrement( f, s [,n] );
  -- Ada:    N/A
  fileId     : identifier;
  theFile    : resPtr;
  keyExpr  : unbounded_string;
  keyType  : identifier;
  amtExpr  : unbounded_string;
  amtType  : identifier;
  hasAmt   : boolean := false;
  oldItem  : unbounded_string;
  oldItemValue : long_float;
begin
  if rshOpt then
     err( "decrement not allowed in a " & optional_bold( "restricted shell" ) );
  end if;
  expect( hash_decrement_t );
  ParseFirstFileParameter( fileId );
  if getUniType( identifiers( fileId ).genKind ) /= uni_numeric_t then
     err( "increment requires a numeric item type" );
  end if;
  ParseNextStringParameter( keyExpr, keyType, uni_string_t );
  if token = symbol_t and identifiers( token ).value = "," then
     hasAmt := true;
     ParseLastNumericParameter( amtExpr, amtType, natural_t );
  elsif token = symbol_t and identifiers( token ).value = ")" then
     expect( symbol_t, ")" );
  else
     err( ", or ) expected" );
  end if;
  if isExecutingCommand then
     begin
       findResource( to_resource_id( identifiers( fileId ).value ), theFile );

       get( theFile.hash.session, to_string( keyExpr ), oldItem );
       -- berkeley throws exception on not found
       --if oldItem /= null_unbounded_string then
          oldItemValue := to_numeric( oldItem );
          if hasAmt then
             put( theFile.hash.session, to_string( keyExpr ),  to_string( to_unbounded_string( oldItemValue - long_float( natural( to_numeric( amtExpr ) ) ) ) ) );
          else
             put( theFile.hash.session, to_string( keyExpr ), to_string( to_unbounded_string( oldItemValue - 1.0 ) ) );
          end if;
       --end if;
     exception when storage_error =>
       err( "storage error raised" );
     when constraint_error =>
       err( "constraint error raised" );
     when msg: berkeley_error =>
       if last_error( theFile.hash.session ) = DB_NOTFOUND then
          err( "key not found" );
       else
          err( exception_message( msg ) );
       end if;
     end;
  end if;
end ParseHashDecrement;

#else

procedure ParseHashDecrement is
begin
  err( "bdb support not configured" );
end ParseHashDecrement;

#end if;
#if BDB

procedure ParseHashAdd is
  -- Syntax: hash.add( f, s, e );
  -- Ada:    N/A
  fileId     : identifier;
  theFile  : resPtr;
  keyExpr  : unbounded_string;
  keyType  : identifier;
  itemExpr : unbounded_string;
  itemType : identifier;
  itemId     : identifier;
  isRecord   : boolean := false;
  isArray    : boolean := false;
  genKindId  : identifier;
begin
  if rshOpt then
     err( "add not allowed in a " & optional_bold( "restricted shell" ) );
  end if;
  expect( hash_add_t );
  ParseFirstFileParameter( fileId );
  ParseNextStringParameter( keyExpr, keyType, uni_string_t );
  expect( symbol_t, "," );
  genKindId := identifiers( fileId ).genKind;
  -- This assumes we don't have aggregate expressions yet.
  -- record?
  if identifiers( getBaseType( genKindId ) ).kind = root_record_t then
     isRecord := true;
     ParseIdentifier( itemId );
     genTypesOk( identifiers( itemId ).kind, genKindId );
  -- array?
  elsif identifiers( genKindId ).list then
     isArray := true;
     ParseIdentifier( itemId );
     genTypesOk( identifiers( itemId ).kind, genKindId );
  -- normal (scalar) expression?
  else
    ParseGenItemParameter( itemExpr, itemType, genKindId );
  end if;
  expect( symbol_t, ")" );
  if isExecutingCommand then
     if isRecord then
        declare
           jsonString : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value ), theFile );
           exists( theFile.hash.session, to_string( keyExpr ) );
        exception when storage_error =>
          err( "storage error raised" );
        when msg: berkeley_error =>
          if last_error( theFile.hash.session ) = DB_NOTFOUND then
             DoRecordToJson( jsonString, itemId );
             put( theFile.hash.session, to_string( keyExpr ), to_string( jsonString ) );
          else
             err( exception_message( msg ) );
          end if;
        end;
     elsif isArray then
        declare
           jsonString : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value ), theFile );
           exists( theFile.hash.session, to_string( keyExpr ) );
        exception when storage_error =>
          err( "storage error raised" );
        when msg: berkeley_error =>
          if last_error( theFile.hash.session ) = DB_NOTFOUND then
             DoArrayToJson( jsonString, itemId );
             put( theFile.hash.session, to_string( keyExpr ), to_string( jsonString ) );
          else
             err( exception_message( msg ) );
          end if;
        end;
     else
        -- normal scalar expression
        begin
           findResource( to_resource_id( identifiers( fileId ).value ), theFile );
           exists( theFile.hash.session, to_string( keyExpr ) );
        exception when storage_error =>
          err( "storage error raised" );
        when msg: berkeley_error =>
          if last_error( theFile.hash.session ) = DB_NOTFOUND then
             put( theFile.hash.session, to_string( keyExpr ), to_string( itemExpr ) );
          else
             err( exception_message( msg ) );
          end if;
        end;
     end if;
  end if;
end ParseHashAdd;

#else

procedure ParseHashAdd is
begin
  err( "bdb support not configured" );
end ParseHashAdd;

#end if;
#if BDB

procedure ParseHashReplace is
  -- Syntax: hash.replace( f, c | k, v );
  -- Ada:    N/A
  -- Note: the key will not be overwritten if a cursor is used
-- TODO: option to throw an exception on missing values (including replace, get, add (existing value)
  fileId     : identifier;
  theFile  : resPtr;
  keyExpr  : unbounded_string;
  keyType  : identifier;
  itemExpr : unbounded_string;
  itemType : identifier;
  itemId     : identifier;
  isRecord   : boolean := false;
  isArray    : boolean := false;
  genKindId  : identifier;
  cursId   : identifier := eof_t;
  theCurs  : resPtr;
begin
  if rshOpt then
     err( "replace not allowed in a " & optional_bold( "restricted shell" ) );
  end if;
  expect( hash_replace_t );
  ParseFirstFileParameter( fileId );
  expect( symbol_t, "," );
  if getbaseType( identifiers( token ).kind ) = hash_cursor_t then
     ParseIdentifier( cursId );
     genTypesOk( identifiers( fileId ).genKind, identifiers( cursId ).genKind );
  else
     ParseExpression( keyExpr, keyType );
     baseTypesOk( keyType, uni_string_t );
  end if;
  expect( symbol_t, "," );
  genKindId := identifiers( fileId ).genKind;
  -- This assumes we don't have aggregate expressions yet.
  -- record?
  if identifiers( getBaseType( genKindId ) ).kind = root_record_t then
     isRecord := true;
     ParseIdentifier( itemId );
     genTypesOk( identifiers( itemId ).kind, genKindId );
  -- array?
  elsif identifiers( genKindId ).list then
     isArray := true;
     ParseIdentifier( itemId );
     genTypesOk( identifiers( itemId ).kind, genKindId );
  -- normal (scalar) expression?
  else
    ParseGenItemParameter( itemExpr, itemType, genKindId );
  end if;
  expect( symbol_t, ")" );
  if isExecutingCommand then
     if cursId /= eof_t then
        -- put where the cursor is
        if isRecord then
           declare
              jsonString : unbounded_string;
           begin
             findResource( to_resource_id( identifiers( fileId ).value ), theFile );
             findResource( to_resource_id( identifiers( cursId ).value ), theCurs );
             DoRecordToJson( jsonString, itemId );
             put( theFile.hash.session,
                  theCurs.hash_cur,
                  keyExpr, -- this is ignored
                  jsonString,
                  DB_C_PUT_CURRENT );
           exception when msg: berkeley_error =>
             err( exception_message( msg ) );
           end;
        elsif isArray then
           declare
              jsonString : unbounded_string;
           begin
             findResource( to_resource_id( identifiers( fileId ).value ), theFile );
             findResource( to_resource_id( identifiers( cursId ).value ), theCurs );
             DoArrayToJson( jsonString, itemId );
             put( theFile.hash.session,
                  theCurs.hash_cur,
                  keyExpr, -- this is ignored
                  jsonString,
                  DB_C_PUT_CURRENT );
           exception when msg: berkeley_error =>
             err( exception_message( msg ) );
           end;
        else
           begin
             findResource( to_resource_id( identifiers( fileId ).value ), theFile );
             findResource( to_resource_id( identifiers( cursId ).value ), theCurs );
             put( theFile.hash.session,
                  theCurs.hash_cur,
                  keyExpr, -- this is ignored
                  itemExpr,
                  DB_C_PUT_CURRENT );
           exception when msg: berkeley_error =>
             err( exception_message( msg ) );
           end;
        end if;
     else
       -- put, but only if the target exists
        if isRecord then
           declare
              jsonString : unbounded_string;
           begin
             findResource( to_resource_id( identifiers( fileId ).value ), theFile );
             exists( theFile.hash.session, to_string( keyExpr ) );
             DoRecordToJson( jsonString, itemId );
             put( theFile.hash.session, to_string( keyExpr ), to_string( jsonString ) );
           exception when storage_error =>
             err( "storage error raised" );
           when msg: berkeley_error =>
              if last_error( theFile.hash.session ) /= DB_NOTFOUND then
                 err( exception_message( msg ) );
              end if;
           end;
        elsif isArray then
           declare
              jsonString : unbounded_string;
           begin
             findResource( to_resource_id( identifiers( fileId ).value ), theFile );
             exists( theFile.hash.session, to_string( keyExpr ) );
             DoArrayToJson( jsonString, itemId );
             put( theFile.hash.session, to_string( keyExpr ), to_string( jsonString ) );
           exception when storage_error =>
             err( "storage error raised" );
           when msg: berkeley_error =>
              if last_error( theFile.hash.session ) /= DB_NOTFOUND then
                 err( exception_message( msg ) );
              end if;
           end;
        else
           begin
             findResource( to_resource_id( identifiers( fileId ).value ), theFile );
             exists( theFile.hash.session, to_string( keyExpr ) );
             put( theFile.hash.session, to_string( keyExpr ), to_string( itemExpr ) );
           exception when storage_error =>
             err( "storage error raised" );
           when msg: berkeley_error =>
              if last_error( theFile.hash.session ) /= DB_NOTFOUND then
                 err( exception_message( msg ) );
              end if;
           end;
        end if;
     end if;
  end if;
end ParseHashReplace;

#else

procedure ParseHashReplace is
begin
  err( "bdb support not configured" );
end ParseHashReplace;

#end if;
#if BDB

procedure ParseHashAppend is
  -- Syntax: hash.append( f, s, e );
  -- Ada:    N/A
  fileId     : identifier;
  theFile  : resPtr;
  keyExpr  : unbounded_string;
  keyType  : identifier;
  itemExpr : unbounded_string;
  itemType : identifier;
  oldItem  : unbounded_string;
begin
  if rshOpt then
     err( "append not allowed in a " & optional_bold( "restricted shell" ) );
  end if;
  expect( hash_append_t );
  ParseFirstFileParameter( fileId );
  if getUniType( identifiers( fileId ).genKind ) /= uni_string_t then
     err( "append requires a string item type" );
  end if;
  ParseNextStringParameter( keyExpr, keyType, uni_string_t );
  ParseLastGenItemParameter( itemExpr, itemType, identifiers( fileId ).genKind );
  if isExecutingCommand then
     begin
       findResource( to_resource_id( identifiers( fileId ).value ), theFile );
       get( theFile.hash.session, to_string( keyExpr ), oldItem );
       put( theFile.hash.session, to_string( keyExpr ), to_string( oldItem & itemExpr ) );
     exception when storage_error =>
       err( "storage error raised" );
     when msg: berkeley_error =>
       if last_error( theFile.hash.session ) /= DB_NOTFOUND then
           err( exception_message( msg ) );
       end if;
     end;
  end if;
end ParseHashAppend;

#else

procedure ParseHashAppend is
begin
  err( "bdb support not configured" );
end ParseHashAppend;

#end if;
#if BDB

procedure ParseHashPrepend is
  -- Syntax: hash.prepend( f, s, e );
  -- Ada:    N/A
  fileId     : identifier;
  theFile  : resPtr;
  keyExpr  : unbounded_string;
  keyType  : identifier;
  itemExpr : unbounded_string;
  itemType : identifier;
  oldItem  : unbounded_string;
begin
  if rshOpt then
     err( "prepend not allowed in a " & optional_bold( "restricted shell" ) );
  end if;
  expect( hash_prepend_t );
  ParseFirstFileParameter( fileId );
  if getUniType( identifiers( fileId ).genKind ) /= uni_string_t then
     err( "append requires a string item type" );
  end if;
  ParseNextStringParameter( keyExpr, keyType, uni_string_t );
  ParseLastGenItemParameter( itemExpr, itemType, identifiers( fileId ).genKind );
  if isExecutingCommand then
     begin
       findResource( to_resource_id( identifiers( fileId ).value ), theFile );
       get( theFile.hash.session, to_string( keyExpr ), oldItem );
       put( theFile.hash.session, to_string( keyExpr ), to_string( itemExpr & oldItem ) );
     exception when storage_error =>
       err( "storage error raised" );
     when msg: berkeley_error =>
       if last_error( theFile.hash.session ) /= DB_NOTFOUND then
           err( exception_message( msg ) );
       end if;
     end;
  end if;
end ParseHashPrepend;

#else

procedure ParseHashPrepend is
begin
  err( "bdb support not configured" );
end ParseHashPrepend;

#end if;
#if BDB

procedure ParseHashFlush is
  -- Syntax: hash.flush( f, flags );
  -- Ada:    bbd.sync( f, flags );
  fileId     : identifier;
  theFile    : resPtr;
begin
  expect( hash_flush_t );
  ParseSingleFileParameter( fileId );
  if isExecutingCommand then
     begin
        findResource( to_resource_id( identifiers( fileId ).value ), theFile );
        sync( theFile.hash.session );
     exception when msg: berkeley_error =>
        err( exception_message( msg ) );
     end;
  end if;
end ParseHashFlush;

#else

procedure ParseHashFlush is
begin
  err( "bdb support not configured" );
end ParseHashFlush;

#end if;
#if BDB

procedure ParseHashTruncate is
  -- Syntax: hash.truncate( f );
  -- Ada:    bbd.sync( f, cnt );
  fileId     : identifier;
  theFile    : resPtr;
begin
  if rshOpt then
     err( "truncate not allowed in a " & optional_bold( "restricted shell" ) );
  end if;
  expect( hash_truncate_t );
  ParseSingleFileParameter( fileId );
  if isExecutingCommand then
     declare
        cnt : natural;
     begin
        findResource( to_resource_id( identifiers( fileId ).value ), theFile );
        truncate( theFile.hash.session, cnt );
        if trace and cnt > 0 then
           put_trace( cnt'img & " records were erased" );
        end if;
     exception when msg: berkeley_error =>
        err( exception_message( msg ) );
     end;
  end if;
end ParseHashTruncate;

#else

procedure ParseHashTruncate is
begin
  err( "bdb support not configured" );
end ParseHashTruncate;

#end if;
#if BDB

procedure ParseHashNewCursor is
  -- Syntax: hash.new_cursor( c, t );
  -- Ada:    N/A
  resId : resHandleId;
  ref : reference;
  genKindId : identifier;
begin
  expect( hash_new_cursor_t );
  ParseFirstOutParameter( ref, hash_cursor_t );
  baseTypesOK( ref.kind, hash_cursor_t );
  expect( symbol_t, "," );
  ParseIdentifier( genKindId );
  if class_ok( genKindId, typeClass, subClass ) then
     --DEBUG
     null;
     --if identifiers( genKindId ).list then
     --   err( "element type should be a scalar type" );
     --elsif identifiers( getBaseType( genKindId ) ).kind = root_record_t then
     --   err( "element type should be a scalar type" );
     --end if;
  end if;
  identifiers( ref.id ).genKind := genKindId;
  expect( symbol_t, ")" );
  if isExecutingCommand then
     identifiers( ref.id ).resource := true;
     declareResource( resId, hash_cursor, blocks_top );
     AssignParameter( ref, to_unbounded_string( resId ) );
  end if;
end ParseHashNewCursor;

#else

procedure ParseHashNewCursor is
begin
  err( "bdb support not configured" );
end ParseHashNewCursor;

#end if;
#if BDB

procedure ParseHashOpenCursor is
  -- Syntax: hash_io.open_cursor( f, c );
  -- Ada:    N/A
  fileId     : identifier;
  theFile    : resPtr;
  cursId     : identifier;
  theCurs    : resPtr;
begin
-- TODO: fold into hash.open
  expect( hash_open_cursor_t );
  ParseFirstFileParameter( fileId );
  ParseLastCursorParameter( cursId );
  if isExecutingCommand then
     findResource( to_resource_id( identifiers( fileId ).value ), theFile );
     findResource( to_resource_id( identifiers( cursId ).value ), theCurs );
     new_berkeley_cursor( theFile.hash.session, theCurs.hash_cur );
  end if;
end ParseHashOpenCursor;

#else

procedure ParseHashOpenCursor is
begin
  err( "bdb support not configured" );
end ParseHashOpenCursor;

#end if;
#if BDB

procedure ParseHashCloseCursor is
  -- Syntax: hash_io.close_cursor( f,c );
  -- Ada:    bdb.close_cursor( f,c );
  fileId     : identifier;
  theFile    : resPtr;
  cursId     : identifier;
  theCurs    : resPtr;
begin
  expect( hash_close_cursor_t );
  ParseFirstFileParameter( fileId );
  ParseLastCursorParameter( cursId );
  if isExecutingCommand then
     begin
        findResource( to_resource_id( identifiers( fileId ).value ), theFile );
        findResource( to_resource_id( identifiers( cursId ).value ), theCurs );
        close( theFile.hash.session, theCurs.hash_cur );
     exception when msg: berkeley_error =>
        err( exception_message( msg ) );
     end;
  end if;
end ParseHashCloseCursor;

#else

procedure ParseHashCloseCursor is
begin
  err( "bdb support not configured" );
end ParseHashCloseCursor;

#end if;
#if BDB

procedure ParseHashFirst is
  -- Syntax: hash_io.first( f, c, k, v );
  -- Ada:    bdb.get( f );
  -- Note: Unlike Ada lists, Berkeley will also return the element when
  -- positioning the cursor.
  -- TODO: open cursor check would prevent storage error messages
  fileId     : identifier;
  theFile    : resPtr;
  cursId     : identifier;
  theCurs    : resPtr;
  keyRef     : reference;
  valRef     : reference;
  isRecord   : boolean := false;
  isArray    : boolean := false;
  genKindId  : identifier;
begin
  if rshOpt then
     err( "get_first not allowed in a " & optional_bold( "restricted shell" ) );
  end if;
  expect( hash_get_first_t );
  ParseFirstFileParameter( fileId );
  ParseNextCursorParameter( cursId );
  genKindId := identifiers( fileId ).genKind;
  genTypesOk( genKindId, identifiers( cursId ).genKind );
  ParseNextOutParameter( keyRef, string_t );
  baseTypesOK( keyRef.kind, string_t );
  expect( symbol_t, "," );
  -- This assumes we don't have aggregate expressions yet.
  -- record?
  if identifiers( getBaseType( genKindId ) ).kind = root_record_t then
     -- ParseOutParam doesn't handle full records or arrays
     isRecord := true;
     ParseIdentifier( valRef.id );
     genTypesOk( identifiers( valRef.id ).kind, genKindId );
  -- array?
  elsif identifiers( genKindId ).list then
     -- ParseOutParam doesn't handle full records or arrays
     isArray := true;
     ParseIdentifier( valRef.id );
     genTypesOk( identifiers( valRef.id ).kind, genKindId );
  else
     -- This will still auto-declare scalar values
     ParseOutParameter(  valRef, genKindId );
  end if;
  expect( symbol_t, ")" );
  if isExecutingCommand then
     if isRecord then
        declare
           key : unbounded_string;
           jsonString : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value ), theFile );
           findResource( to_resource_id( identifiers( cursId ).value ), theCurs );
           get( theFile.hash.session,
                theCurs.hash_cur,
                key,
                jsonString,
                DB_C_GET_FIRST );
           AssignParameter( keyRef, key );
           DoJsonToRecord( valRef.id, jsonString );
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        when STORAGE_ERROR =>
           err( "storage_error raised" );
        when others =>
           raise;
        end;
     elsif isArray then
        declare
           key : unbounded_string;
           jsonString : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value ), theFile );
           findResource( to_resource_id( identifiers( cursId ).value ), theCurs );
           get( theFile.hash.session,
                theCurs.hash_cur,
                key,
                jsonString,
                DB_C_GET_FIRST );
           AssignParameter( keyRef, key );
           DoJsonToArray( valRef.id, jsonString );
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        when STORAGE_ERROR =>
           err( "storage_error raised" );
        when others =>
           raise;
        end;
     else
        declare
           key : unbounded_string;
           data : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value ), theFile );
           findResource( to_resource_id( identifiers( cursId ).value ), theCurs );
           get( theFile.hash.session,
                theCurs.hash_cur,
                key,
                data,
                DB_C_GET_FIRST );
           AssignParameter( keyRef, key );
           AssignParameter( valRef, data );
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        when STORAGE_ERROR =>
           err( "storage_error raised" );
        when others =>
           raise;
        end;
     end if;
  end if;
end ParseHashFirst;

#else

procedure ParseHashFirst is
begin
  err( "bdb support not configured" );
end ParseHashFirst;

#end if;
#if BDB

procedure ParseHashNext is
  -- Syntax: hash_io.next( f, c, k, v );
  -- Ada:    bdb.get( f );
  -- Note: Unlike Ada lists, Berkeley will also return the element when
  -- positioning the cursor.
  fileId     : identifier;
  theFile    : resPtr;
  cursId     : identifier;
  theCurs    : resPtr;
  keyRef     : reference;
  valRef     : reference;
  isRecord   : boolean := false;
  isArray    : boolean := false;
  genKindId  : identifier;
begin
  if rshOpt then
     err( "get_next not allowed in a " & optional_bold( "restricted shell" ) );
  end if;
  expect( hash_get_next_t );
  ParseFirstFileParameter( fileId );
  ParseNextCursorParameter( cursId );
  genKindId := identifiers( fileId ).genKind;
  genTypesOk( genKindId, identifiers( cursId ).genKind );
  ParseNextOutParameter( keyRef, string_t );
  baseTypesOK( keyRef.kind, string_t );
  expect( symbol_t, "," );
  -- This assumes we don't have aggregate expressions yet.
  -- record?
  if identifiers( getBaseType( genKindId ) ).kind = root_record_t then
     -- ParseOutParam doesn't handle full records or arrays
     isRecord := true;
     ParseIdentifier( valRef.id );
     genTypesOk( identifiers( valRef.id ).kind, genKindId );
  -- array?
  elsif identifiers( genKindId ).list then
     -- ParseOutParam doesn't handle full records or arrays
     isArray := true;
     ParseIdentifier( valRef.id );
     genTypesOk( identifiers( valRef.id ).kind, genKindId );
  else
     -- This will still auto-declare scalar values
     ParseOutParameter(  valRef, genKindId );
  end if;
  expect( symbol_t, ")" );
  if isExecutingCommand then
     if isRecord then
        declare
           key : unbounded_string;
           jsonString : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value ), theFile );
           findResource( to_resource_id( identifiers( cursId ).value ), theCurs );
           get( theFile.hash.session,
                theCurs.hash_cur,
                key,
                jsonString,
                DB_C_GET_NEXT );
           AssignParameter( keyRef, key );
           DoJsonToRecord( valRef.id, jsonString );
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        when STORAGE_ERROR =>
           err( "storage_error raised" );
        when others =>
           raise;
        end;
     elsif isArray then
        declare
           key : unbounded_string;
           jsonString : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value ), theFile );
           findResource( to_resource_id( identifiers( cursId ).value ), theCurs );
           get( theFile.hash.session,
                theCurs.hash_cur,
                key,
                jsonString,
                DB_C_GET_NEXT );
           AssignParameter( keyRef, key );
           DoJsonToArray( valRef.id, jsonString );
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        when STORAGE_ERROR =>
           err( "storage_error raised" );
        when others =>
           raise;
        end;
     else
        declare
           key : unbounded_string;
           data : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value ), theFile );
           findResource( to_resource_id( identifiers( cursId ).value ), theCurs );
           get( theFile.hash.session,
                theCurs.hash_cur,
                key,
                data,
                DB_C_GET_NEXT );
           AssignParameter( keyRef, key );
           AssignParameter( valRef, data );
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        when STORAGE_ERROR =>
           err( "storage_error raised" );
        when others =>
           raise;
        end;
     end if;
  end if;
end ParseHashNext;

#else

procedure ParseHashNext is
begin
  err( "bdb support not configured" );
end ParseHashNext;

#end if;
#if BDB

procedure ParseHashLast is
  -- Syntax: hash_io.last( f, c, k, v );
  -- Ada:    bdb.get( f );
  -- Note: Unlike Ada lists, Berkeley will also return the element when
  -- positioning the cursor.
  fileId     : identifier;
  theFile    : resPtr;
  cursId     : identifier;
  theCurs    : resPtr;
  keyRef     : reference;
  valRef     : reference;
  isRecord   : boolean := false;
  isArray    : boolean := false;
  genKindId  : identifier;
begin
  if rshOpt then
     err( "get_last not allowed in a " & optional_bold( "restricted shell" ) );
  end if;
  expect( hash_get_last_t );
  ParseFirstFileParameter( fileId );
  ParseNextCursorParameter( cursId );
  genKindId := identifiers( fileId ).genKind;
  genTypesOk( genKindId, identifiers( cursId ).genKind );
  ParseNextOutParameter( keyRef, string_t );
  baseTypesOK( keyRef.kind, string_t );
  expect( symbol_t, "," );
  -- This assumes we don't have aggregate expressions yet.
  -- record?
  if identifiers( getBaseType( genKindId ) ).kind = root_record_t then
     -- ParseOutParam doesn't handle full records or arrays
     isRecord := true;
     ParseIdentifier( valRef.id );
     genTypesOk( identifiers( valRef.id ).kind, genKindId );
  -- array?
  elsif identifiers( genKindId ).list then
     -- ParseOutParam doesn't handle full records or arrays
     isArray := true;
     ParseIdentifier( valRef.id );
     genTypesOk( identifiers( valRef.id ).kind, genKindId );
  else
     -- This will still auto-declare scalar values
     ParseOutParameter(  valRef, genKindId );
  end if;
  expect( symbol_t, ")" );
  if isExecutingCommand then
     if isRecord then
        declare
           key : unbounded_string;
           jsonString : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value ), theFile );
           findResource( to_resource_id( identifiers( cursId ).value ), theCurs );
           get( theFile.hash.session,
                theCurs.hash_cur,
                key,
                jsonString,
                DB_C_GET_LAST );
           AssignParameter( keyRef, key );
           DoJsonToRecord( valRef.id, jsonString );
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        when STORAGE_ERROR =>
           err( "storage_error raised" );
        when others =>
           raise;
        end;
     elsif isArray then
        declare
           key : unbounded_string;
           jsonString : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value ), theFile );
           findResource( to_resource_id( identifiers( cursId ).value ), theCurs );
           get( theFile.hash.session,
                theCurs.hash_cur,
                key,
                jsonString,
                DB_C_GET_LAST );
           AssignParameter( keyRef, key );
           DoJsonToArray( valRef.id, jsonString );
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        when STORAGE_ERROR =>
           err( "storage_error raised" );
        when others =>
           raise;
        end;
     else
        declare
           key : unbounded_string;
           data : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value ), theFile );
           findResource( to_resource_id( identifiers( cursId ).value ), theCurs );
           get( theFile.hash.session,
                theCurs.hash_cur,
                key,
                data,
                DB_C_GET_LAST );
           AssignParameter( keyRef, key );
           AssignParameter( valRef, data );
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        when STORAGE_ERROR =>
           err( "storage_error raised" );
        when others =>
           raise;
        end;
     end if;
  end if;
end ParseHashLast;

#else

procedure ParseHashLast is
begin
  err( "bdb support not configured" );
end ParseHashLast;

#end if;
#if BDB

procedure ParseHashPrevious is
  -- Syntax: hash_io.previous( f, c, k, v );
  -- Ada:    bdb.get( f );
  -- Note: Unlike Ada lists, Berkeley will also return the element when
  -- positioning the cursor.
  fileId     : identifier;
  theFile    : resPtr;
  cursId     : identifier;
  theCurs    : resPtr;
  keyRef     : reference;
  valRef     : reference;
  isRecord   : boolean := false;
  isArray    : boolean := false;
  genKindId  : identifier;
begin
  if rshOpt then
     err( "get_previous not allowed in a " & optional_bold( "restricted shell" ) );
  end if;
  expect( hash_get_previous_t );
  ParseFirstFileParameter( fileId );
  ParseNextCursorParameter( cursId );
  genKindId := identifiers( fileId ).genKind;
  genTypesOk( genKindId, identifiers( cursId ).genKind );
  ParseNextOutParameter( keyRef, string_t );
  baseTypesOK( keyRef.kind, string_t );
  expect( symbol_t, "," );
  -- This assumes we don't have aggregate expressions yet.
  -- record?
  if identifiers( getBaseType( genKindId ) ).kind = root_record_t then
     -- ParseOutParam doesn't handle full records or arrays
     isRecord := true;
     ParseIdentifier( valRef.id );
     genTypesOk( identifiers( valRef.id ).kind, genKindId );
  -- array?
  elsif identifiers( genKindId ).list then
     -- ParseOutParam doesn't handle full records or arrays
     isArray := true;
     ParseIdentifier( valRef.id );
     genTypesOk( identifiers( valRef.id ).kind, genKindId );
  else
     -- This will still auto-declare scalar values
     ParseOutParameter(  valRef, genKindId );
  end if;
  expect( symbol_t, ")" );
  if isExecutingCommand then
     if isRecord then
        declare
           key : unbounded_string;
           jsonString : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value ), theFile );
           findResource( to_resource_id( identifiers( cursId ).value ), theCurs );
           get( theFile.hash.session,
                theCurs.hash_cur,
                key,
                jsonString,
                DB_C_GET_PREV );
           AssignParameter( keyRef, key );
           DoJsonToRecord( valRef.id, jsonString );
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        when STORAGE_ERROR =>
           err( "storage_error raised" );
        when others =>
           raise;
        end;
     elsif isArray then
        declare
           key : unbounded_string;
           jsonString : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value ), theFile );
           findResource( to_resource_id( identifiers( cursId ).value ), theCurs );
           get( theFile.hash.session,
                theCurs.hash_cur,
                key,
                jsonString,
                DB_C_GET_PREV );
           AssignParameter( keyRef, key );
           DoJsonToArray( valRef.id, jsonString );
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        when STORAGE_ERROR =>
           err( "storage_error raised" );
        when others =>
           raise;
        end;
     else
        declare
           key : unbounded_string;
           data : unbounded_string;
        begin
           findResource( to_resource_id( identifiers( fileId ).value ), theFile );
           findResource( to_resource_id( identifiers( cursId ).value ), theCurs );
           get( theFile.hash.session,
                theCurs.hash_cur,
                key,
                data,
                DB_C_GET_PREV );
           AssignParameter( keyRef, key );
           AssignParameter( valRef, data );
        exception when msg: berkeley_error =>
           err( exception_message( msg ) );
        when STORAGE_ERROR =>
           err( "storage_error raised" );
        when others =>
           raise;
        end;
     end if;
  end if;
end ParseHashPrevious;
#else

procedure ParseHashPrevious is
begin
  err( "bdb support not configured" );
end ParseHashPrevious;

#end if;
#if BDB

procedure ParseHashWillRaise( result : out unbounded_string; kind : out identifier ) is
  -- Syntax: b := hash.will_raise( f );
  -- Ada:    N/A
  fileId     : identifier;
  theFile    : resPtr;
begin
  kind := boolean_t;
  expect( hash_will_raise_t );
  ParseSingleFileParameter( fileId );
  if isExecutingCommand then
     begin
        findResource( to_resource_id( identifiers( fileId ).value ), theFile );
        result := to_bush_boolean( will_raise( theFile.hash.session ) );
     exception when berkeley_error =>
        result := to_bush_boolean( false );
     end;
  end if;
end ParseHashWillRaise;

#else

procedure ParseHashWillRaise( result : out unbounded_string; kind : out identifier ) is
begin
  err( "bdb support not configured" );
end ParseHashWillRaise;

#end if;
#if BDB

procedure ParseHashLastError( result : out unbounded_string; kind : out identifier ) is
  -- Syntax: n := hash_io.last_error( f );
  -- Ada:    N/A
  fileId     : identifier;
  theFile    : resPtr;
begin
  kind := bdb_db_error_t;
  expect( hash_last_error_t );
  ParseSingleFileParameter( fileId );
  if isExecutingCommand then
     begin
        findResource( to_resource_id( identifiers( fileId ).value ), theFile );
        result := to_unbounded_string( db_error'image( last_error( theFile.hash.session ) ) );
     exception when msg: berkeley_error =>
        err( exception_message( msg ) );
     end;
  end if;
end ParseHashLastError;

#else

procedure ParseHashLastError( result : out unbounded_string; kind : out identifier ) is
begin
  err( "bdb support not configured" );
end ParseHashLastError;

#end if;
#if BDB

procedure ParseHashRaiseExceptions is
  -- Syntax: hash_io.raise_exceptions( f, b );
  -- Ada:    bdb.raise_exceptions
  -- this is impacted by --trace
  fileId     : identifier;
  theFile    : resPtr;
  boolExpr   : unbounded_string;
  boolType   : identifier;
begin
  expect( hash_raise_exceptions_t );
  ParseFirstFileParameter( fileId );
  ParseLastEnumParameter( boolExpr, boolType, boolean_t );
  if isExecutingCommand then
     declare
       raise_them : boolean := boolExpr = to_unbounded_string( "1" );
     begin
        findResource( to_resource_id( identifiers( fileId ).value ), theFile );
        raise_exceptions( theFile.hash.session, raise_them, boolean( traceOpt ) );
     exception when msg: berkeley_error =>
        err( exception_message( msg ) );
     end;
  end if;
end ParseHashRaiseExceptions;

#else

procedure ParseHashRaiseExceptions is
begin
  err( "bdb support not configured" );
end ParseHashRaiseExceptions;

#end if;

-----------------------------------------------------------------------------

procedure StartupHashIO is
begin
  declareNamespace( "hash_io" );

  declareIdent( hash_file_t,   "hash_io.file", positive_t, typeClass );
  declareIdent( hash_cursor_t, "hash_io.cursor", positive_t, typeClass );
  declareIdent( hash_db_error_t, "hash_io.db_error", natural_t, typeClass );

  declareProcedure( hash_new_file_t,  "hash_io.new_file", ParseHashNewFile'access );
  declareProcedure( hash_clear_t,     "hash_io.clear",    ParseHashClear'access );

  declareProcedure( hash_create_t,    "hash_io.create",   ParseHashCreate'access );
  declareProcedure( hash_close_t,     "hash_io.close",    ParseHashClose'access );
  declareProcedure( hash_open_t,      "hash_io.open",     ParseHashOpen'access );
  declareFunction(  hash_is_open_t,   "hash_io.is_open",  ParseHashIsOpen'access );
  declareFunction(  hash_name_t,      "hash_io.name",     ParseHashName'access );
  declareProcedure( hash_delete_t,    "hash_io.delete",   ParseHashDelete'access );
  declareProcedure( hash_flush_t,     "hash_io.flush",    ParseHashFlush'access );
  declareProcedure( hash_truncate_t,  "hash_io.truncate",  ParseHashTruncate'access );

  declareProcedure( hash_set_t,       "hash_io.set",      ParseHashSet'access );
  declareProcedure( hash_get_t,       "hash_io.get",      ParseHashGet'access );
  declareFunction(  hash_has_element_t, "hash_io.has_element",  ParseHashHasElement'access );
  declareProcedure( hash_remove_t,    "hash_io.remove",      ParseHashRemove'access );
  declareProcedure( hash_increment_t, "hash_io.increment",ParseHashIncrement'access );
  declareProcedure( hash_decrement_t, "hash_io.decrement",ParseHashDecrement'access );
  declareProcedure( hash_add_t,       "hash_io.add", ParseHashAdd'access );
  declareProcedure( hash_replace_t,   "hash_io.replace", ParseHashReplace'access );
  declareProcedure( hash_append_t,    "hash_io.append", ParseHashAppend'access );
  declareProcedure( hash_prepend_t,   "hash_io.prepend", ParseHashPrepend'access );

  declareProcedure( hash_new_cursor_t,  "hash_io.new_cursor", ParseHashNewCursor'access );
  declareProcedure( hash_open_cursor_t,  "hash_io.open_cursor", ParseHashOpenCursor'access );
  declareProcedure( hash_close_cursor_t,  "hash_io.close_cursor", ParseHashCloseCursor'access );
  declareProcedure( hash_get_first_t,     "hash_io.get_first", ParseHashFirst'access );
  declareProcedure( hash_get_next_t,      "hash_io.get_next", ParseHashNext'access );
  declareProcedure( hash_get_previous_t,  "hash_io.get_previous", ParseHashPrevious'access );
  declareProcedure( hash_get_last_t,      "hash_io.get_last", ParseHashLast'access );

  declareFunction( hash_will_raise_t, "hash_io.will_raise",  ParseHashWillRaise'access );
  declareFunction( hash_last_error_t, "hash_io.last_error",  ParseHashLastError'access );
  declareProcedure( hash_raise_exceptions_t, "hash_io.raise_exceptions", ParseHashRaiseExceptions'access );

-- TODO: assemble and disassemble - are they helpful for potentially huge trees?
-- TODO: clear (cursor) - just for consistency
-- TODO: truncate
-- TODO: reset?  are in_file, etc. helpful to define here?

  declareNamespaceClosed( "hash_io" );

end StartupHashIO;

procedure ShutdownHashIO is
begin
  null;
end ShutdownHashIO;

end parser_hash_io;
